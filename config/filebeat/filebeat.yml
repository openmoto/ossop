# This file configures our central log shipper, Filebeat.

# Section 1: Static Inputs
# These are specific log files that we always want to collect.
filebeat.inputs:
- type: log
  paths:
    # This tells Filebeat to read the Wazuh alerts file.
    - /var/log/wazuh-alerts/*.json
  # These settings ensure the JSON alerts are parsed correctly.
  json.keys_under_root: true
  json.add_error_key: true
  json.message_key: log
  tags: ["wazuh-alerts"]

- type: log
  paths:
    # This tells Filebeat to read the Suricata alerts and events file.
    - /var/log/suricata/eve.json
  json.keys_under_root: true
  json.add_error_key: true
  tags: ["suricata-ids"]

# Section 2: Dynamic Inputs
# This tells Filebeat to automatically discover and collect logs from
# any other Docker containers running on the host.
filebeat.autodiscover:
  providers:
    - type: docker
      templates:
        - condition:
            contains.docker.container.id: "*"
          config:
            - type: container
              paths:
                - /var/lib/docker/containers/${data.docker.container.id}/*.log

# Section 3: Processors
# These enrich the log data before it's sent.
processors:
  # This adds Docker metadata (like container name) to each log.
  - add_docker_metadata: {}

# Section 4: Output
# This defines where to send all the collected logs.
output.elasticsearch:
  # The 'hosts' value is dynamically set by an environment variable from docker-compose.yml
  hosts: ["http://${OPENSEARCH_HOSTNAME}:${OPENSEARCH_PORT_API}"] 
  # This tells Filebeat how to name the daily indices in OpenSearch.
  index: "filebeat-%{[agent.version]}-%{+yyyy.MM.dd}"

